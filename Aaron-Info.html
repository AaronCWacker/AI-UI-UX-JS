Below is a faithful Markdown outline transcription of the image you shared, converted into emoji-coded, structured Markdown.
I preserved all visible facts, names, groupings, and model variants as shown.

ğŸš€ Future of AI & State of the Art (2026)
ğŸ§  LLMs, Coding, Scaling Laws

(Including models released in 2025+)

Legend

ğŸŸ¦ Open-weight models

ğŸŸ¨ Closed models

ğŸŸ¨ Google

Gemini 2.0 Flash

Gemini 2.0 Pro

Gemini 2.0 Flash-Lite

ShieldGemma 2

Gemini Robotics

Gemma 3 4B

Gemma 3 1B

Gemma 3 12B

Gemma 3 27B

Gemini 2.5 Pro

Flash Preview

Gemini 2.5 Pro Deep Think

Gemma 3n E2B

Gemma 3n E4B

MedGemma 4B

Mistral Small 3.2

MedGemma 27B

Gemini 2.5 Flash

Gemini 2.5 Flash-Lite

Gemini 2.5 Flash Image

Gemma 3 270M

EmbeddingGemma 308M

MultilingualGemma 1B

Gemini 2.5 Flash Preview 0924

Gemini 3 Pro

Gemini 3 Deep Think

Gemini 3 Flash

T5Gemma v2

FunctionGemma 270M

ğŸŸ¨ OpenAI

o3-mini

GPT-4.5 (Orion)

o1-pro

gpt-4o-transcribe

gpt-4o-mini-transcribe

gpt-4o-mini-tts

GPT-4.1

GPT-4.1 Mini

GPT-4.1 Nano

o4-mini

o3-pro

o3-deep-research

o4-mini-deep-research

GPT-OSS-120B

GPT-OSS-20B

GPT-5

GPT-5 Mini

GPT-5 Nano

GPT-5 Pro

GPT-5.2 Instant

GPT-5.2 Pro

GPT-5.2 Thinking

ğŸŸ¨ Microsoft

Phi-4-multimodal

Phi-4-mini

Phi-4-reasoning

Phi-4-reasoning-plus

Phi-4-mini-reasoning

Phi-4-mini-flash-reasoning

ğŸŸ¨ xAI

Grok 3

Grok 3 mini

Aurora

Grok 3 API

Grok 4

Grok 4 Heavy

grok-code-fast-1

Grok 4 Fast

Grok 4.1

Grok 4.1 Fast

ğŸŸ¦ Hugging Face

SmolLM3 3B

ğŸŸ¦ LG AI Research

Reka Flash 3.1

ğŸŸ¦ Moondream

Moondream 3

ğŸŸ¦ Naver

2025X Think13 models

ğŸŸ¦ StepFun

Step-Audio-EditX 3B

ğŸŸ¦ Tencent

Hunyuan3D

ğŸŸ¦ Yandex

Alice AI LLM 1.0

ğŸŸ¦ Allen AI

OLMo 3 7B

OLMo 3 32B

ğŸŸ¨ Anthropic

Claude 3.7 Sonnet

Claude Opus 4

Claude Sonnet 4

Claude Opus 4.1

Claude Sonnet 4.5

Claude Haiku 4.5

Claude Opus 4.5

ğŸŸ¦ Moonshot AI

Kimi K1.5

Kimi K2-Base

Kimi K2-Instruct

Kimi K2-Instruct-0905

Kimi Linear

Kimi K2 Thinking

ğŸŸ¦ Zhipu AI

GLM-4-32B-0414

GLM-2-32B-0414

GLM-4-9B-0414

GLM-Z1-9B

GLM-Z1-Rumination-32B-0414

GLM-4.1V-9B-Thinking

GLM-4.1V-Thinking

GLM-4.5

GLM-4.5-Air

GLM-4.5V

GLM-4.6V

GLM-4.6V-Flash

GLM-4.7

ğŸŸ¦ ByteDance

Doubao-1.5-pro-32k

Doubao-1.5-lite-32k

ğŸŸ¦ AI21 Labs

Jamba 1.6

Jamba 1.7 Mini

Jamba 1.7 Large

Jamba Instruct

Jamba Reasoning 3B

ğŸŸ¦ Nous Research

Hermes 4 14B

Hermes 4 70B

ğŸŸ¦ Alibaba (Qwen Series)

Qwen2.5-VL-3B-Instruct

Qwen2.5-VL-7B-Instruct

Qwen2.5-VL-72B-Instruct

Qwen2.5-Max

QwQ-32B

Qwen2.5-VL-32B-Instruct

Qwen2.5-Omni-7B

Qwen3-0.6B

Qwen3-4B

Qwen3-14B

Qwen3-30B-A3B

Qwen3-1.7B

Qwen3-8B

Qwen3-32B

Qwen3-235B-A22B

Qwen3-Omni-3B

Qwen3-4B-Instruct-2507

Qwen3-30B-A3B-Thinking-2507

Qwen3-235B-A22B-Thinking-2507

Qwen3-30B-A3B-Instruct-2507

Qwen3-235B-A22B-Instruct-2507

Qwen3-Coder-480B-A35B-Instruct

Qwen3-Max

Qwen3-Next-80B-A3B-Instruct

Qwen3-Next-80B-A3B-Thinking

Qwen3-Omni

Qwen3-VL-235B-A22B-Instruct

Qwen3-VL-235B-A22B-Thinking

Qwen3-VL-32B

Qwen3Guard-8B

Qwen3Guard-4B

ğŸŸ¦ Mistral AI

Mistral Saba

Mistral Small 3.1

Devstral Small

Mistral Medium 3

Mistral Small 3.2

Magistral Medium

Magistral Small

4.0 30B

Devstral Medium

Voxtral Small

Voxtral Mini

Medium 3.1

Codestral 2508

Mistral Large 3

Ministral 3B Base

Ministral 3B Reasoning

Mistral Large 3 Base

Ministral 8B Base

Ministral 8B Instruct

Ministral 14B Base

Ministral 14B Reasoning

Devstral Small 2

Ministral 8B Reasoning

Ministral 14B Instruct

Devstral 2

ğŸŸ¦ DeepSeek

DeepSeek-R1

DeepSeek-R1-Zero

DeepSeek-R1-Distill-Qwen-Series

DeepSeek-R1-Distill-Llama-Series

Janus-Pro-1B

Janus-Pro-7B

DeepSeek-V3-0324

DeepSeek-Prover-V2-671B

DeepSeek-Prover-V2-7B

DeepSeek-R1-0528

DeepSeek-R1-0528-Qwen3

DeepSeek-V3.1

DeepSeek-V3.1-Terminus

DeepSeek-V3.2-Exp

DeepSeek-Math-V2

DeepSeek-V3.2

ğŸŸ¨ IBM

Phi-4-multimodal

Granite 3.2 8B-Instruct

TDT 0.6B v2

Granite 4.0 Tiny

Moondream 3

Granite 4.0

Alice AI LLM 1.0

Granite 4.0 Nano 350M

Granite 4.0 Nano 1.5B

ğŸŸ¨ Amazon

Act

Amazon Nova Sonic

Amazon Nova Premier

Amazon Nova 2 Pro

Amazon Nova 2 Omni

ğŸ Apple

Apple Foundation Model (AFM) On-Device

Apple Foundation Model (AFM) Server

ğŸ“Œ Notes

This chart mixes frontier closed models with open-weight research lines

Shows clear trends toward:

ğŸ§  Reasoning-first variants

ğŸ§© Multimodal + Omni models

âš¡ Flash / Thinking / Research SKUs

ğŸ“ Scaling across 0.3B â†’ 600B+ parameter ranges

If you want, next steps could be:

ğŸ§­ Condense into a â€œmodel family treeâ€

ğŸ“Š Tag by capability (reasoning, coding, vision, agents)

ğŸ§  Overlay scaling-law implications

ğŸ›°ï¸ Map this onto your All.AI constellation
